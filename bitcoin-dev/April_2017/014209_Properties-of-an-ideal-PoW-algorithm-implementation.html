<!doctype html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
    <title>Atom Feed Display</title>
    <link rel="stylesheet" href="../../archive_styles.css">
</head>

<body BGCOLOR="#fffffb">
    
    <h1>Properties of an ideal PoW algorithm &amp; implementation</h1>
    <hr class="solid">
    
    <ul>
        
        
            <p><b>Author:</b> praxeology_guy 2017-04-18 19:14:05
            <br><i>Published on: 2017-04-18T19:14:05+00:00</i></p>

        
        

        
        
        <li>
        <a href="/bitcoin-dev/April_2017/combined_Properties-of-an-ideal-PoW-algorithm-implementation.html"> Combined Summary of all posts in thread </a>
        </li>
        
        <li>
            
                <a href="https://lists.linuxfoundation.org/pipermail/bitcoin-dev/2017-April/014209.html">Click here to read original discussion on the bitcoin-dev mailing list</a>
            
        </li>

    </ul>

    <hr>
    <h3> Summary:</h3>
    <p>The cost of producing a chip is dependent on the number of metal layers required to route interconnects in a particular area. Fewer layers mean quicker and easier manufacturing, and fewer patentable costs. A paper discussing various factors impacting chip design costs has been linked, although its validity cannot be vouched for.To minimize asicboost-like optimizations, there needs to be early nonce mixing with variable-length input that has near-constant work. The entirety of the input should be mixed with the nonce data as soon as possible to prevent unexpected optimizations. A hash algorithm with more linear computation time versus input size would be ideal. It would consist of a first-stage Merkle tree hash to pre-lossy-mix-compress the variable length input stream to the size of the second-stage state vector. Each bit of input should have about equal influence on each of the output bits. Then there would be multi-round mixing of the second stage, which would be significantly more work than the first stage.This two-stage algorithm is similar to what is currently done in Bitcoin by the PoW doing SHA256 twice in serial. However, if Bitcoin did SHA256 three or four times or more, then ASICBoost like optimizations would have less of an effect. Designing hardware that can handle a variable-length input is challenging, so it's better to make assumptions about block header size, such as being exactly 80 bytes or something reasonable. Supporting very large input sizes requires a tradeoff between memory/parallelization and die space.</p>
    <hr>
    <p><i> Updated on: 2023-06-12T00:30:04.613572+00:00 </i></p>
    
    

    <footer>
        <span style="font-family: Arial, Helvetica, sans-serif;">&#10084;&#65039;</span> <a href="https://chaincode.com" target="_blank" rel="noreferrer" style="text-decoration: none; color: inherit;">Chaincode</a>
    </footer>
</body>

</html>